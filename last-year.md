Daniel Huggins  this is the single 2024 qualifying projects from our successful R&D Claim.  Can you mock up the 2025 ones for me using ChatGPT please? Thanks
Qualifying R&D Projects
Total of 1 R&D projects undertaken during this claim period:
LLM Structured Decomposition Feasibility Study
PROJECT 1: LLM Structured Decomposition Feasibility Study
 Engineering and technology > Electrical engineering, electronic engineering, information engineering
Completed
 Existing technological and scientific solutions and knowledge
The Developing Leaders Partnership Limited (“DLP”, trading name: TextAlchemy) specialises in the development of software that enables businesses to make informed decisions and develop their leadership skills. For example, if the goal were to achieve ‘X’, the team’s AI model would devise different ways to approach this objective in a multi-step manner via queries. 
At the start of the claim period (Jan 2024), the team of competent professionals reviewed the publicly available knowledge and capabilities around large language models (LLMs) and related technologies. In their assessment, the team came across Langchain, a software library for the composable use of LLMs (i.e. breaking down and orchestrating multiple AI models); however, upon testing, they found that it lacked the ability to effectively track which prompts were sent to which set of AIs. Upon further investigation, the team found that this technological limitation was attributed to Langchain’s use of implicit state, meaning the conversation state was managed internally without clear visibility. Additionally, the team found that data moving through Langchain was unstructured, meaning it generated unreliable outputs. 
On account of these technological limitations, the team sought to undertake an R&D programme to develop a solution based on two existing systems (OpenAI and Anthropic) that would use clearly defined data structures and types to ensure consistency and reliability. Additionally, there would be clear observability, meaning every step of the process would be transparent and trackable. Furthermore, the targeted solution would include a built-in verification process to ensure that mechanisms were in place to confirm that each step was executed correctly.
The team of competent professionals was led by Dan Huggins, the co-founder of DLP. Dan holds a master’s degree in mathematics from Durham University (2:1) and has 13 years of experience working in the field. With regards to the team’s internal knowledge and capabilities, they have had prior proficiency with LLMs and experience with existing modular approaches such as retrieval-augmented generation (RAG).
 Technological and scientific objectives
The technological advance sought was the creation of a new AI-based system with increased verbal reasoning and document analysis capabilities. The creation of this system represented an increase in overall knowledge and capability in the field and, therefore, aligns with Paragraph 9(b) of the BEIS Guidelines. 
To achieve the advance and as part of the advance, the team needed to develop the system to be able to utilise a process (known as decomposition) to break specific scenarios down into smaller, manageable and structured components, orchestrate analysis, and map a proposed solution back to the original query space. If successful, this would enable the system to reliably solve larger, more complex scenarios than other AI systems would be able to resolve in a single step. 
With regard to disseminating the team’s findings, patenting was not considered a viable option. Therefore, the team elected to make the developed framework (RetortJS) open-source, thus enabling public access. The framework devised within this R&D project may also have uses in other fields either as a point of reference or a foundation for future technological advances.
Overall, the R&D work undertaken represented an advance relative to the baseline knowledge and capabilities that existed in the public domain. Consequently, the R&D efforts are in alignment with Paragraphs 6 and 20 of the BEIS Guidelines.
 Technological and scientific uncertainties
Technological uncertainty centred around how to design and develop a new AI-based system with verbal reasoning and document analysis capabilities. Within this overarching uncertainty existed a number of smaller, more specific uncertainties. The following section provides examples of these: 
(1) Specific technological uncertainty existed in how to engineer a practical, reliable method for breaking down complicated language queries using a structured framework that is adaptable, verifiable, and resilient; this was uncertain due to the absence of publicly available frameworks for verifying the suitability of LLM responses and avoiding inherent bias. An AI’s self-assessment was considered an uncertainty because transformer-based generative models process language based on their training data, the data of which can potentially introduce bias. 
(2) Additional technological uncertainty lay in how to integrate data structuring and type-safety with LLMs; this was classified as an uncertainty because while it was clear that existing solutions, such as JSON-schemas, XML schemas, class-based models, failed to combine readability, observability and verifiability in a single scheme, it was not apparent whether such a viable solution could be created. 
(3) Further technological uncertainty revolved around how to develop the system to be able to trace or identify prompts which are sent to the LLMs while also allowing a certain degree of flexibility. This was anticipated to be challenging due to a lack of knowledge and capabilities around existing technologies, such as Langchain.
(4) To compound the above technological uncertainties, it was uncertain how to effectively use the LLMs to reliably validate the work of the model itself while minimising bias, both from human interpretation (cognitive bias) and from the model's training data (training set bias). 
(5) Technological uncertainty centred around how to integrate an adaptable toolchain into an ecosystem that is predominately built around NodeJS; this uncertainty stemmed from a lack of existing industry support for advanced Javascript-based prompt chaining. 
Work done to overcome these technological uncertainties is described in the next section.
 R&D activities to resolve technical and scientific challenges
In an effort to overcome the aforementioned technological uncertainties, the team of competent professionals elected to undertake a programme of R&D, which encompassed a variety of workflows, including information structuring, process orchestration, validation and verification, and observability. Given the size and scope of the R&D efforts, the following highlights work undertaken to resolve the most complex and uncertain aspects, showcasing both the significant challenges involved and the experimental approach taken:
To overcome technological uncertainty in how to represent the overall structure of a scenario in a human-readable format, which was also adaptable and succinct, the team investigated using Zod, a tool designed for defining and validating data structures in a way that prioritises compatibility with Typescript. During the subsequent R&D activities, the team developed a proof-of-concept (PoC) using Zod to structure two specific test scenarios. Although the team successfully used this PoC system to create a technically correct representation of the scenarios, the outcome was difficult for humans to understand. After analysing the issue, the team realised that the scenarios contained a combination of two types of information: (1) Declarative/data, information that describes what something; and (2) imperative/instructive, information that describes what to do.
In an attempt to resolve this uncertainty, the team instead looked at using Mongoose models, which provide both data fields and the possibility of instance methods to represent operations on the model. During the R&D efforts, the team developed a second PoC model using Mongoose and examined one specific test scenario. While the new PoC was an improvement over Zod, Mongoose’s use of class-like structures did not appear suitable for the scenario paradigm. That is, Mongoose had a number of similarities with object-oriented classes/templates, which were considered too flexible and abstract. In addition, validation was purely data-based and lacked the ability to control the combination of actions or instructions (imperative elements) within a given scenario. Further, the team developed a fluent Javascript domain-specific language (DSL) that served as a new server wrapper framework (named ‘RetortJS’) to embody scenarios which combined elements of both Zod and Mongoose approaches; this version was eventually successful in accurately representing the targeted scenarios in a flexible manner that also allowed for automated validation and reversible decomposition (i.e. the ability to break down a scenario into its constituent parts and then reassemble it back into its original form).
During the R&D activities, the team looked at how to overcome technological uncertainty around decomposing a language query into its essential elements in a way that was both observable (i.e. each of the elements had discernible meaning/value) and orthogonal. Orthogonality was crucial in order to allow each element or facet of the query to be dealt with independently in a multi-step process, and then recomposed without introducing distortions. 
In order to resolve this, the team adopts a similar approach to traditional 'principle components analysis' whereby a higher-dimensional space can be 'folded' or 'projected' onto a reduced set of dimensions while maintaining the majority of the informational content/meaning of the original. Later, the folder response could be reversed and reverted back into the original query space. Using this approach, the team developed a new PoC semantic framework with a reduced scope in Javascript code so as to provide a set of relatively orthogonal dimensions against which to decompose queries. The intention was that an LLM could be relied upon to identify and decompose queries in this way. Upon inspection, the team observed that while the developed solution succeeded for a subset of possible scenarios, the level of effort expended was significant, due to components being identified 'by hand'. In future work, the team would look to identify and explore the viability of automated alternatives, such as developing composite embeddings (i.e. embeddings of whole phrases or sentences) using knowledge already encoded within the language models.
In the latter stages of the claim period the team of competent professionals began to combine elements of the different work streams to develop a viable PoC software solution which attempted to achieve the goals of the project; however, work remains ongoing. 
At the end of the claim period (Dec 24), the team managed to produce a viable platform for decomposing and solving language-based problems. However, several technological uncertainties remain that are ongoing into the next claim period; for example, it was technologically uncertain how to reliably automate the decomposition of queries across a wide range of topics and situations. Another uncertainty was how to validate, either using LLMs or other methods, that the responses were appropriate within the context of the original query. Additional uncertainty lay in whether Lanchain could be reliably extended or adapted for use in the decomposition process. Overall, the R&D project continued into the next claim period.